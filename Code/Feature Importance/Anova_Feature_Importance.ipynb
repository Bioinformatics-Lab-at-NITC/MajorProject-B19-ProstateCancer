{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# classification model using Anova.\n",
        "\n",
        "The first function txt_csv is used to convert a text file to a csv file. The function takes two parameters, the path of the text file and the filename of the csv file to be created.\n",
        "\n",
        "Next, the converted csv file is read using Pandas and any missing values are removed.\n",
        "\n",
        "The transpose function is used to convert the rows into columns and columns into rows.\n",
        "\n",
        "The MinMaxScaler function from the scikit-learn library is used to scale the data to a range of 0 to 1.\n",
        "\n",
        "The 'sample type' column is created by extracting the last two characters from each column name and sorting the data by the 'sample type' column in descending order.\n",
        "\n",
        "The 'sample type' column is converted to binary values and the index of the data is reset.\n",
        "\n",
        "The 'X' variable is created by dropping the 'sample type' column from the data, while the 'y' variable is set as the 'sample type' column.\n",
        "\n",
        "The code uses Anova feature selection to select important features from the input data. "
      ],
      "metadata": {
        "id": "1pyEEFHcbw0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the library\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Function to convert text file to CSV format\n",
        "# When the raw data is in txt format\n",
        "def txt_csv(path, filename):\n",
        "    # Open the text file\n",
        "    with open(path) as in_file:\n",
        "        # Remove any extra whitespace from each line\n",
        "        stripped = (line.strip() for line in in_file)\n",
        "        # Split each line using tab as delimiter and create a list of lists\n",
        "        lines = (line.split(\"\\t\") for line in stripped if line)\n",
        "        # Create a new CSV file with the given filename and write the list of lists to it\n",
        "        with open(filename+'.csv', 'w') as out_file:\n",
        "            writer = csv.writer(out_file)\n",
        "            writer.writerows(lines)\n",
        "\n",
        "# Call the txt_csv function to convert the text file to CSV\n",
        "txt_csv(\"/content/miR_norm.counts (2).csv\", 'omics')\n",
        "\n",
        "# Read the converted CSV file into a Pandas dataframe\n",
        "raw_data = pd.read_csv('omics.csv')\n",
        "\n",
        "# Drop any rows with missing values\n",
        "raw_data = raw_data.dropna()\n",
        "\n",
        "# Transpose the dataframe to make the samples the rows and the attributes the columns\n",
        "data = raw_data.transpose()\n",
        "\n",
        "# Scale the values of each attribute to be between 0 and 1 using MinMaxScaler\n",
        "# When the data is not normalized\n",
        "scaler = MinMaxScaler()\n",
        "data[list(data.columns.values)] = scaler.fit_transform(data[list(data.columns.values)])\n",
        "\n",
        "# Extract the sample types from the row names and add them as a new column in the dataframe\n",
        "sample_type = []\n",
        "column_names = data.index\n",
        "for name in column_names[:]:\n",
        "    sample_type.append(name[13:15])\n",
        "data['sample type'] = sample_type\n",
        "\n",
        "# Replace the sample type labels with 0 and 1\n",
        "data['sample type'] = data['sample type'].replace(['11'],0)\n",
        "data['sample type'] = data['sample type'].replace(['01'],1)\n",
        "\n",
        "# Reset the index and remove the column names\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data.columns.name = None\n",
        "\n",
        "# Separate the features (attributes) and target (sample type) into separate dataframes\n",
        "X = data.drop(\"sample type\",1)\n",
        "y = data[\"sample type\"] \n",
        "\n",
        "# Creating a SelectKBest object with a score function of f_classif and selecting 250 features\n",
        "fs = SelectKBest(score_func=f_classif, k=250)\n",
        "# Applying feature selection to the input features X and target variable y\n",
        "X_selected = fs.fit_transform(X, y)\n",
        "# Converting the transformed input features to a DataFrame\n",
        "anv = pd.DataFrame(X_selected)\n",
        "# Creating an empty list to store the gene names\n",
        "genes = []\n",
        "\n",
        "# Looping over each column of the transformed input features\n",
        "for j in range(len(anv.columns)):\n",
        "  # Looping over each feature in the original input features\n",
        "  for i in tqdm(range(len(X.columns))):\n",
        "    # Checking if the values in the i-th feature of X are equal to the values in the j-th column of the transformed features\n",
        "    if list(X.iloc[:,i]) == list(anv.iloc[:,j]):\n",
        "      # If the values are equal, the name of the i-th feature is added to the list of gene names\n",
        "      genes.append(X.columns[i])\n",
        "\n",
        "# Converting the list of gene names to a DataFrame\n",
        "gene = pd.DataFrame(genes)\n",
        "\n",
        "# Writing the gene names to a CSV file\n",
        "gene.to_csv('annova.csv',index=False)"
      ],
      "metadata": {
        "id": "IlytkbWRcdy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0CZOAFnpeofs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}