{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# classification model using XGBoost library.\n",
        "\n",
        "The first function txt_csv is used to convert a text file to a csv file. The function takes two parameters, the path of the text file and the filename of the csv file to be created.\n",
        "\n",
        "Next, the converted csv file is read using Pandas and any missing values are removed.\n",
        "\n",
        "The transpose function is used to convert the rows into columns and columns into rows.\n",
        "\n",
        "The MinMaxScaler function from the scikit-learn library is used to scale the data to a range of 0 to 1.\n",
        "\n",
        "The 'sample type' column is created by extracting the last two characters from each column name and sorting the data by the 'sample type' column in descending order.\n",
        "\n",
        "The 'sample type' column is converted to binary values and the index of the data is reset.\n",
        "\n",
        "The 'X' variable is created by dropping the 'sample type' column from the data, while the 'y' variable is set as the 'sample type' column.\n",
        "\n",
        "The XGBoost classifier is used to build the model and the feature importances are calculated and sorted in descending order.\n",
        "\n",
        "The top 143 features with the highest importance are saved to a csv file named 'xgboost.csv'."
      ],
      "metadata": {
        "id": "1pyEEFHcbw0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the library\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Function to convert text file to CSV format\n",
        "# When the raw data is in txt format\n",
        "def txt_csv(path, filename):\n",
        "    # Open the text file\n",
        "    with open(path) as in_file:\n",
        "        # Remove any extra whitespace from each line\n",
        "        stripped = (line.strip() for line in in_file)\n",
        "        # Split each line using tab as delimiter and create a list of lists\n",
        "        lines = (line.split(\"\\t\") for line in stripped if line)\n",
        "        # Create a new CSV file with the given filename and write the list of lists to it\n",
        "        with open(filename+'.csv', 'w') as out_file:\n",
        "            writer = csv.writer(out_file)\n",
        "            writer.writerows(lines)\n",
        "\n",
        "# Call the txt_csv function to convert the text file to CSV\n",
        "txt_csv(\"/content/miR_norm.counts.csv\", 'omics')\n",
        "\n",
        "# Read the converted CSV file into a Pandas dataframe\n",
        "raw_data = pd.read_csv('omics.csv')\n",
        "\n",
        "# Drop any rows with missing values\n",
        "raw_data = raw_data.dropna()\n",
        "\n",
        "# Transpose the dataframe to make the samples the rows and the attributes the columns\n",
        "data = raw_data.transpose()\n",
        "\n",
        "# Scale the values of each attribute to be between 0 and 1 using MinMaxScaler\n",
        "# When the data is not normalized\n",
        "scaler = MinMaxScaler()\n",
        "data[list(data.columns.values)] = scaler.fit_transform(data[list(data.columns.values)])\n",
        "\n",
        "# Extract the sample types from the row names and add them as a new column in the dataframe\n",
        "sample_type = []\n",
        "column_names = data.index\n",
        "for name in column_names[:]:\n",
        "    sample_type.append(name[13:15])\n",
        "data['sample type'] = sample_type\n",
        "\n",
        "# Replace the sample type labels with 0 and 1\n",
        "data['sample type'] = data['sample type'].replace(['11'],0)\n",
        "data['sample type'] = data['sample type'].replace(['01'],1)\n",
        "\n",
        "# Reset the index and remove the column names\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data.columns.name = None\n",
        "\n",
        "# Separate the features (attributes) and target (sample type) into separate dataframes\n",
        "X = data.drop(\"sample type\",1)\n",
        "y = data[\"sample type\"] \n",
        "\n",
        "# Initialize an XGBClassifier model and fit it to the data\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Extract the feature importances from the model and save them to a CSV file\n",
        "importances = pd.DataFrame(data={\n",
        "    'Attribute': X.columns,\n",
        "    'Importance': model.feature_importances_\n",
        "})\n",
        "importances = importances.sort_values(by='Importance', ascending=False)\n",
        "# Number of features selected depends upon the result\n",
        "# Here 143 features will be selected\n",
        "im = importances[:143]\n",
        "im['Attribute'].to_csv('xgboost.csv',index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlytkbWRcdy0",
        "outputId": "383d8303-ba8b-44b4-c96f-8874d6ace936"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-8f0e9f9fb3ba>:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['sample type'] = sample_type\n",
            "<ipython-input-5-8f0e9f9fb3ba>:55: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  X = data.drop(\"sample type\",1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0CZOAFnpeofs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}